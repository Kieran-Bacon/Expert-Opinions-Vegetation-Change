% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
\geometry{margin=1.5in}
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
\setlength{\parskip}{0mm}

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{enumitem}
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
%%%Bibliography
\usepackage{cite}
\bibliographystyle{abbrv}

%%%Packages that I have added
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color}
\usepackage[section]{placeins}
\usepackage{setspace}

%%%Packages that I (Paul) have added
\usepackage{url}

%\usepackage{mcode}
%%% END Article customizations

%%% The "real" document content comes below...
\newcommand{\diff}[2]{\frac{d{#1}}{d{#2}}}
\newcommand{\pd}[2]{\frac{\partial{#1}}{\partial{#2}}}
\newcommand{\pds}[2]{\frac{\partial^{2}{#1}}{\partial^{2}{#2}}}
\newcommand{\tendist}{\,{\buildrel d \over \longrightarrow}\,}
\newcommand{\E}{\mathbb{E}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\Var}{\mathop{\rm Var}}
\newcommand{\Cov}{\mathop{\rm Cov}}
\newcommand{\U}{\mathbf{U}_{1}}
\newcommand{\Ut}{\mathbf{U}^{T}}
\newcommand{\X}{\textbf{X}}
\newcommand{\K}{\textbf{K}}
\newcommand{\Z}{\textbf{Z}}
\newcommand{\W}{\textbf{W}}
\newcommand{\La}{{\bf \Lambda}}


\makeatletter
\newcommand{\vast}{\bBigg@{3.5}}
\newcommand{\Vast}{\bBigg@{5}}
\makeatother

\numberwithin{equation}{section}
\newtheorem{theorem}{Theorem}[section]
\renewcommand{\indent}{\hspace*{15pt}\ignorespaces}



\title{ECMM427 - Group Project Course work 1}
\author{Project specification and plan}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}

\pagestyle{empty}
\tableofcontents
\clearpage
\pagestyle{fancy}
\setcounter{page}{1}
\maketitle

\section{Problem definition}

As the information about the state of our environment becomes more readily available, the conversations humanity are having about the correct course of actions to take regarding our impact becomes ever more inclusive and expansive. Our understanding of the systems that affect our climate have so far been very useful in predicting the changes that have occurred, however they are by no means entirely accurate and more to the point, the models that are created do not all agree on the trends and the impacts of those systems. This discrepancy is a focus point of some to illustrate a lack of understanding of the subject, but this is likely due to subtle differences in the simplification of the natural world. The climate models in current use span decades of engineering and understanding and are formed from a aggregate of climate model systems. Depending on the task at hand, a subset of the total models are used to generate a prediction.\\

\indent In the endeavour to improve our models predictive capability, with a future goal to reduce the variance of prediction results, many iterations of the models are produced and run. Each iteration testing the effect of varies possible changes, for example: input parameters are adjusted; a more realistic representation for climate systems are used; and improved historical data is operated on. This results in a large collection of climate model outputs, with no discernible way of determining which offers the best prediction or insight . The task of deciding whether the changes have caused an improvement becomes a discussion point of a group of researchers, demanding a great portion of time. They are required to compare the merits of each model so that they can be ordered relatively. This process is one they hope to automate with the use of machine learning techniques\\


Yass bitch

.\\

Problem definition ::
\begin{enumerate}
\item As information in a domain increases, so does the complexity of the models used to model said domains.
\item Through the introduction other climate related components, large volumes of modes are produced and they are increasingly more complex. The task of identifying which model best represents the present and future becomes more of a challenge.
\item Climate research is a vast field that is critical in predicting the violent hidden nature of weather systems, what environmental factors tend to increase this behaviour, and what we can expect from the natural world as we continue to inhabit and apply change to the world.
\item The met office produce hundreds of models every year that try and include new forms of statistical data with the intention of increasing our confidence in what the future holds.
\item These models are evaluated by a team of experts that look to see how well it predicts the known past with a hope in finding a model that shall predict the future of Earth's Climate.
\item These models however tend to have huge variance over their final outputs which highlights the fact the system is complex and hard to replicate.
\item Experts are looking to make use of machine learning techniques to help in the refinement of this process by replacing the cumbersome requirement for human time and discussion on what the merits of each model. The machine would help choose models by minicing experts opinions.
\item Along with that, a easy to use web tool that facilitates the interaction between the experts and the machine such that they might get the most out of its operation.
\end{enumerate}


\section{Solution specification}

\subsection{Web tool}

\begin{enumerate}
\item Experts would like to be able to annotate their opinion on models.
\item Experts would like to upload models to be evaluated.
\item Evaluation should come with the functionality to toggle on and off other expert opinions.
\item Personal expert dashboards and examination.
\end{enumerate}

\section{Maintenance Plan}
This section will cover what measures will be taken to ensure that the software artefact is well maintained throughout the project and after the project is completed. Maintaining the software artefact entails ensuring that all its features remain up to date and remain in the scope of the project and also ensures that the addition of new features does not break other features or render them obsolete.\par

An agile approach to development ensures good maintenance of the project on the macro scale. All new features are discussed and directly assessed by the problem owner so that they are guaranteed to be in scope of the project and the scope itself is also regularly revised. On top of this, the developers are split to manage different features of the project therefore ensuring that all features work together in a cohesive fashion. On the micro scale, frequent testing using automated and manual methods further ensures the artefact is well maintained during the project. A Bitbucket repository will be used for version control allowing simultaneous development of multiple features and protects from errors caused by new code through the use of rollback functionality.\par

Once the project is completed, the required long term maintenance is low. The learner will continue to improve using automated online learning and its performance can be monitored and validated by expert opinion to ensure that the learner is still accurate. The architecture of the webtool and back-end system is designed to be as flexible as possible when it comes to updates or repairs by avoiding close coupling of the system and planning for future addition of new features and scalability. Regular checks for bugs in the webtool and monitoring the performance of the server throughout automated checks is enough to maintain the artefact.

\section{Cost/benefit analysis}
As this is a research focused project, there is no plan to sell or monetise the intellectual property of the software artefact at the end of the project timeline. Rather, this project adheres to a more open source approach. The webtool and all it’s functionality will be free to access and use and it is planned that the machine learners will improve over time from continual use after this project is completed. Therefore, in order to create a cost/benefit analysis which is relevant to this project, the most significant ‘currency’ counts as developer or climate expert time since time spent on this project is time taken away from other projects.

\subsection{Development costs}
A significant intial cost to this project and most other machine learning based projects is the time taken to pre-process an appropriate data set for training and testing of the learner. For this project a supervised learning approach is used therefore training and testing of the model requires labelled data. In the case of this project, the data (output from surface vegetation models) must be given a score by experts for multiple questions therefore, each vegetation model must be labelled multiple times. When training a machine learner, the larger the training (and testing) data set, the more reliable the learner predictions will be. Hence, this initial cost can be very large however the larger this cost, the better the pay-off is further down the development of the project. This cost can be partly offset by incrementally adding to the labelled data set as development progresses. To begin with, vegetation model outputs can be labelled once a prototype webtool is set up and used for preliminary testing of the prototype learner with the aim of increasing the size of the labelled set as much and as soon as possible.\par

This project follows an agile approach to development therefore frequent meetings with the project owner are necessary throughout the development phase of the project. Meetings with the project owner happen on a weekly basis thus creating an additional cost with regards to the project owners time. An agile approach to development also means that testing and maintenance of the software artefact happens simultaneously to development. And so the pre-completion maintenance costs of the software artefact must be taken into account. The work involved in the pre-completion maintenance of the software artefact is described in the aforementioned maintenance plan. The cost of testing the software artefact for this project factors in solely for user acceptance tests (UATs) as these require the project owner themselves to test an iteration of the product.\par

A dedicated server is required since the only interface between the user and the learner is the webtool. The server is required from the development phase so that development can take place in the appropriate environment and that reliable tests can be carried out. During the development of the software artefact, the webtool will be hosted on university provided server space therefore the server cost is the resources taken away from other potential uses.\par

The final significant cost to be considered is the time devoted by us, the developers, towards the completion of this project. Time spent on this project is time spent away from other potential projects.

\subsection{Post-completion costs}
Once the development phase is complete, there are still maintenance costs to consider. General upkeep of the webtool and planned or unplanned patches and improvements. Once the webtool is available to the wider scientific community there is the inevitability of required bug fixes to account for as well as planning for performance checks to ensure the learner is appropriately adjusting to new labelled data sets and making accurate predictions on ‘real’ data.\par

Post-completion the server keeping the webtool operational will be the main running cost. The artefact will be given over to the project owner who will then be responsible hosting the server. The use of Docker will ensure that the artefact runs regardless of the underlying architecture therefore will be easily portable to other hosts. Furthermore, Docker allows easy scaling of the system according to demand.\par

The ability of the learner to carry out online learning means that training can continue post-completion. However this means that experts time is still required to label new data so that the prediction of the learner can be improved. However this cost has less impact compared to the development phase since the learner is already trained to an acceptable standard therefore any further training carried out post development, although still important has less impact on the performance of the learner.\par

\subsection{Benefits}
The goal of this project is to provide an efficient way of choosing the best models using a large selection of model outputs. The model outputs represent the observed effects of surface vegetation on carbon feedbacks over the last 200 years. These model outputs are relatively cheap to obtain as they are based on existing observational data hence they can be run a large number of times. However running these models into the future is expensive and requires greater computational power. This computational power is expensive to use therefore only the best models should be chosen. Creating an efficient method to select these models will save the expense of using sub-optimal models for future predictions.\par

Furthermore, by efficiently sorting model outputs, expert time is saved from manual sorting. Hence one of the main benefits of this project is to save expert time spent manually qualifying model outputs by using a machine learner to do this sorting automatically. The long term aim is that the expert time spent labelling data is largely outweighed by the time saved by this automation. On top of this, expert knowledge on model output analysis will be available to the public in a far more accessible way.\par

In an agile approach to software development, having the problem owner closely involved with the development process ensures that the scope of the project is well defined and that the software artefact is always meeting the problem owners requirements. Agile development also allows for flexibility of the project, new functionality can be added or removed throughout the development without major backtracking. This is valuable for this project in particular where the final requirements have a degree of flexibility and the requirements may change during the development process. And so the cost of the project experts time is outweighed by the benefit of a more efficient and flexible development process leading to a better end result.\par

Using an online learning approach means that the learner can be improved over time without input from the developers. Re-training of the model is not necessary and so a significant portion of learner maintenance is done automatically. New labelled data sets can only be supplied by trusted experts therefore the continuous learning is reliable.\par

Using Docker for this project offers easy scalability as the software artefact can run independently of its environment. Therefore the webtool can easily be ported from the university provided servers to another dedicated server. (\path{https://success.docker.com/Architecture/Docker_Reference_Architecture%3A_Designing_Scalable%2C_Portable_Docker_Container_Networks})


\section{Ethical Considerations}

Ethical, legal and professional considerations are important for any
software engineering project. Machine learning and data driven systems
require an extra level of care due to legal aspects of handling data,
as well as the ethical aspects of the decisions that are derived from
it. This project has a very specific set of issues that should be
dealt with as the project itself is designed to simulate the professional
opinions of experts, something that has both the potential for abuse
and consequently potentially damaging consequences for the professional. 

\subsection{Project Specific}

In this subsection, issues that relate directly to this project will
be coupled with proposed courses of action to give a full picture
of the issues and the decisions that the development team will make
to overcome them. 

\subsubsection{Ethical}

The core ethical issues of this project fall into four categories. 
\begin{itemize}
\item Ethical issues relating to the misrepresentation of academic experts
opinions and the knock on effects of this on their careers.
\item The potential for this system to be used maliciously.
\item The potential for inaccuracies in the system to effect scientific
results or influence legislation. 
\item Holding of personal information.
\end{itemize}

\paragraph{Misrepresentation of opinions.}

The underlying principle of this project is to generalise a researchers
opinions and preferences to estimate what their opinion is of unseen
data. Whilst this can be extremely useful in time saving these so
researchers time and not having to give their opinions on every single
piece of data it has the potential to drastically misrepresent the
opinions of these experts. In the worst case, having their name attached
to opinions that are not representative of their own may be damaging
very to their career. To mitigate against this risk it is suggested
that the page that produces inference results will include a disclaimer
that clearly states that whilst the results produced during the inference
step is supposed to represent their opinions it is not their opinion
and may sometimes not produce a faithful representation. As an additional
safeguard at the training phase, metrics such as accuracy or correlation
metrics calculated on a validation set will be shown to the expert
before he/she decides whether to publish his ``opinion predictor''
to be usable by the public. It is believed that these two safeguards
will mitigate the risk as much as possible. 

\paragraph{Inaccuracies in the system effecting scientific results or influence
legislation. }

Related to the above point is the capabilities of the system to bias
scientific results and as a result potentially influence legislative
decisions about climate change. The solution to this is likely the
same as the above point, including disclaimers that the produced results
are not necessarily 100\% representative. 

\paragraph{Malicious Usage}

Climate change is a very contentious topic that has been shown to
drive people to extreme lengths to fight for their side of the argument,
even to the extent of spending vast amounts of money or committing
crimes to convince people of their opinion <references>. As a result
of this it must be ensured that the system is:
\begin{itemize}
\item As secure against hacking as possible and keeping thorough logs of
usage to help understand what has been compromised upon a breach.
\item Enforcing that accounts cannot be set up in the names of others so
that they can impersonate them. 
\item A method of disambiguating experts with the same name, eg. Institution
\item Some form of verification status. This may be as simple as verifying
that account holders for the ``experts'' possess {*}.ac.{*}, {*}.gov
or {*}.edu email addresses. 
\end{itemize}
Alternatively to the above ideas, it may be possible to simply restrict
the availability of account creation to invite only. As was seen in
the Climategate scandal, keeping the science open to the public is
beneficial in the long run as it ensures clarity that no facts are
being hidden. For this reason it should be possible for any interested
party to access the inference section of the site if required, it
would also be beneficial to describe methodology for the machine learning
element on the website in a way that is accessible to non-machine
learning experts.

\subsubsection{Legal }

The data held in as a result of this project is believed to be covered
under the Data Protection Act 1998 and the new General Data Protection
Regulation (GDPR) 2016 due to the ability to identify the individual
given the information, both explicit and implied that is retained in
the user accounts of the web tool. Eg. Name and Email which when combined
with the knowledge of the field of research would make it very trivial
to find out precisely who the information relates to. For the purposes
of this section the GDPR will be specifically focused on due to its
replacement of the Data Protection Act on the 25th May 2018. The GDPR
states that any ways the data will be used or processed should be
transparent and clearly presented to the user. It also states that
the information should be viewable by the user and have the ability
to be updated should it be found to be inaccurate or deleted upon
request. All of these points have fairly trivial solutions such as
clear disclaimers and a simple accounts page showing all the information
stored relating to that user as well as a delete account button to
cover the right to erasure. 

Something that is a more interesting for this context is the right
to explanation that states that a user has the right to explanation
about decisions that are made using their data. This is interesting
as in some machine learning systems it is extremely difficult, if
not impossible, to explain the decision that have learned from the
data to make. Luckily article 9(2) allows somebody to explicitly consent
to forego this right. In this case this is probably very likely to
be the solution that is taken it is very possible however that certain
algorithms such as decision trees or KNN may offer suitably explainable
algorithms and asking the user to waiver this right may not be necessary. 

\subsubsection{Summary of Terms and Conditions Requirements.}

For somebody who is going to be using the systems as a non-expert
to label climate model run:
\begin{itemize}
\item Consenting their awareness that the algorithm is not to be assumed
to give a totally faithful representation of an experts opinion for
all cases.
\end{itemize}
For experts who are labelling data must consent to the above as well
as:
\begin{itemize}
\item Consenting for their personal information to be held and their ``opinions''
offered to the general public.
\item Waiving their rights to explanation on how decisions are made based
on their data. Note, an explanation of the algorithms used to make
the decisions will be shown, but it may not be possible to show how
these algorithms make the decisions they do which appears to be in
violation.
\end{itemize}

\paragraph{Software License Agreements}

Consideration must be taken throughout the development process to use
only libraries that are free to use for academic work. //TODO

\subsubsection{Professional}

A large consideration that needs to be made is on the professional
responsibilities of taking on a project such as this. This project
is a very high risk endeavour whereby it is very possible that there
are real limitations that are baked into underlying limits of the world
such as information theory and therefore no amount of clever engineering
will ever be able to solve. An example of this kind of problem is
that it might be the case that the machine learning aspect of performing
the desired inference on this data requires so much data that attempting
to represent the opinions of a single expert may be completely infeasible
due to the volumes of samples that the expert might need to label. 

\subsection{Domain Specific}

\subsubsection{Ethical}

Technology and more prominently machine learning has the unfortunate
potential byproduct of significantly reducing the number of skilled
jobs in certain fields, either by making people's jobs easier and
therefore reducing the skill required or by removing them all together.
Cases of this have been seen in areas from robots replacing factory
workers all the way though to uber researching autonomous vehicles
gearing up to replace their human drivers. Fortunately this is a non-issue
in this case due to the fact that for the people who the developed
system will be ``imitating'', assigning rankings to climate model
data is a tiny and likely unenjoyable slice of their job. The rest bite
from this process will allow them to focus more on their core research
and make more valuable contributions to the field. 

\subsubsection{Legal}

\subsection{Development Approach}
\quad This project will be completed using an Agile methodology. Agile has been chosen because it allows for not only changes to the time plan, but to changes in requirements/desires of the “customer”. Other module projects and the generally packed lives of the collaborators to this project will no doubt cause changes to when different components to be complete. This factor along with the evolving idea of what is wanted, and possible, correspond well with the Agile methodology.\par

\quad Python has been chosen as the language to develop the machine learner in. The reasoning behind this choice is that all group members have at least some experience working with the language, and others even have experience using it for machine learning. Python’s sckit-learn module also comes with many prebuild machine learning techniques that are easy to comprehend and use.\par

\quad In addition to the basic web development tools like HTML, CSS, and Bootstrap we have decide to use Python Pylons Pyramid. Pylons is an open source Web Framework written in python. The decision to use this as the backend framework came from the fact that the learner will be written in python allowing for easy integration. Also a group member already has experience in using this framework, making it the obvious choice.\par

\subsection{Milestones}

\begin{itemize}

\item API(ASAP) – The API must be created and agreed upon first. This is the backbone to all the programming that will be done during this project and is what will allow us to work individually without running into compatibility issues later down the line. At this point we already have a draft of the API and are working out differences in opinion, and filling gaps.

\item CA1 (10/11/2017) – 
Frontend Skeleton ()– The website pages are created with little to no functionality. Just a visual representation to give us a sense of what needs to be developed for each page, alongside how the site should be navigated.

\item Backend Skeleton () –  The server for the site is up and running and a database has been created to store the relevant data that will be used in the project. 

\item Data visualization () –  This will be a crucial element in the collecting of data. The models have outputs of up to 17 vegetation types, all of which cannot be visualized at the same time. Without this visualization it would be very difficult for an expert to discern the good outputs from the bad outputs, and even if they could it would be too time consuming.

\item Data Collection Functionality () – The page where an expert comes in and gives their opinion is fully functional. This includes visual representation of the models, user input, and data capture. Completion of this milestone is instrumental in the development of the rest of the project. Currently we have no data on the opinions of experts and without data we cannot develop a machine learning technique.

\item Basic Learner () – Once the data collection is up and running we can begin to develop our learner. At this point the technique used by the learner does not need to be permanent, but a functioning learner is needed so that other components can begin development.

\item Chosen Set of Algorithms () – After a learner has been created we can start experimenting with the different types of machine learning algorithms. Through this experimentation we will come up with a single/small set of machine learning algorithms that users can choose from.

\item Training Stage Complete () – At this point an expert should be able to login to the site, give their opinions on models, have those opinions trained into a learner, and use that model to provide opinions on new models. This element can begin development once the data collection and basic learner are completed.

\item Upload/Result Page Complete – Anyone should be able to come to the site, upload models, select an expert, and get the results from that expert’s learner. At this point the site is fully functional.

\item Final Report (11/05/2018) –

\item Presentation and Demonstration (second half of term 3) –

\subsection{Risk Analysis}

\quad The main risk that this project will face is time management. The entire project is on a short time span, being that it needs to be completed by May 2018. That relatively short amount of time on top of the busy lives of the group members does not leave a lot of wiggle room when it comes to getting different components completed. Up to this point the group has been able to meet regularly with any real hassle. This will most likely become more difficult as the term progresses and other modules start to give out more work. \par

\quad The next risk will be lack of data. At present, we have no data to train a learner on. This would not be too large a problem if we could generate the data ourselves, but the group’s ability to do so will be limited, considering that only Dr F Hugo Lambert is the only expert among us. In light of this the development of the Data collection process is crucial, so that we can start collecting data. With a large amount of data there is no guarantee that the learning methods that we implement will be able to accurately represent the experts. With a lack of data, it could prove very hard to find a correlation between model ratings and expert opinion.\par

\quad Other risks to the project include lack of communication outside of term time, differences in opinion among group members, change in requirements late in the development process. The largest of these being the lack of communication outside of term time. The group members all live in different areas, there is even members who reside outside of the U.K. and time zones may make communication sporadic. \par

\quad For fall back plans the first thing to go will be the unnecessary components, such as output on the features that the learner believes the expert to find most important. Further fallback could end up with the use of only one learner as opposed to a set.\par

\subsection{Stuff written for Maintenance and C/B Analysis}

\subsubsection{Maintenance}
\quad For maintaining code, a Bitbucket repository has been created. This will allow individuals within the group to upload new code, as well as keeping existing code up to date.  Not only does Bitbucket create a secure site where loss of work is not a concern, but it also allows for rollbacks in case of errors caused by new code.\par

\quad The server for our website will be given to us by the University. This cuts maintenance for the group because the University will be in charge of keeping the server running and setting up any needed software. The server will have a SQLite database to store the opinions of experts and the learner models. (Possible duplicate DB as back up?)\par

\quad After the project comes to a close, the server, data, and code will be given over to Dr F Hugo Lambert/the University. He and whomever he chooses to work with will then be responsible for the further development and maintenance of the code, data, and site.\par


\subsubsection{C/B Analysis}

\quad There are minimal costs to this project. The main cost will be the time spent by the group members and leaders. Since the group members are all students their time is not very costly. The group leaders such as Dr F Hugo Lambert and Prof Jonathan Fieldsend are much more so, but they will be spending a significantly smaller amount of time working on it. The other cost of this project is the money spent by the University on running and maintaining the server that our website will be hosted from. Again this is a very minimal cost considering that the University already has the equipment and would be maintaining anyway. The only real cost to the school would be setting up our space on the server, a onetime small task.\par

\quad The benefits of this project far out weight the costs. The rating of models is a time consuming process, and time is a precious commodity to the experts that would be scoring models. With this project we hope to accurately represent the opinions of these experts. With this representation the work that would take the real experts hours even days would be done in mere seconds. On top of this the knowledge of these experts can now be easily accessible to the world. \par

\quad A current problem with the rating of models that not all models share the same views on what is “good” and what is “bad”. With the use of our tool the collaborative opinion of the experts can be approximated. Through our website a database of model ratings will be built. Using the same machine learning technique that represents the opinion of a single expert we intend to represent the collaborative, by training the learner with the combined data of all the experts.\par




\end{document}
